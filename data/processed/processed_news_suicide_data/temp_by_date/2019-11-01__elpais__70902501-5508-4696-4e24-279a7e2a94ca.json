{"_id":"5dea3b93dec1220e27375a88","page":0,"fullpage":false,"headline":"Trevor Paglen: ¿Qué ven las máquinas? ¿Cómo nos clasifican?","date":"2019-11-01T11:20:55.026Z","content":"Trevor Paglen: ¿Qué ven las máquinas? ¿Cómo nos clasifican?\n\nA Trevor Paglen (1974, Camp Springs, Estados Unidos) se le conoce por indagar en lo que no se ve a través de lo que se ve. Geógrafo de formación, su obra abarca la fotografía, la escultura, el periodismo de investigación, la escritura, la ingeniería y otras disciplinas con el fin de poner al descubierto los entresijos y coordenadas de aquello a lo que se refiere como el “mundo negro”, esa parcela de nuestro entorno que por distintos motivos permanece oculta. El artista ha pasado más de dos décadas fotografiando la geografía política clandestina, las estructuras invisibles del poder que apuntalan nuestro día a día: bases de entrenamiento militar y prisiones que no figuran en los mapas, así como sistemas de recopilación de datos y de vigilancia que incluyen satélites, cables de banda ancha sumergidos en el mar, o máquinas de inteligencia artificial. Así, sus últimos años se han centrado en el estudio de las llamadas imágenes de entrenamiento: conjunto de imágenes utilizadas para enseñar a las máquinas de inteligencia artificial (IA) cómo “ver” y cómo categorizar el mundo.\nSon dos las exposiciones que recogen el trabajo del versátil artista: Training Humans, la primera exhibición dedicada a las imágenes de entrenamiento, concebida junto a la investigadora y profesora universitaria Kate Crawford, se exhibe en la Fundación Prada de Milán; y From ‘Apple’ to ‘Anomaly ‘puede verse en el Barbican Centre de Londres. Cuando hace dos años Paglen y Crawford iniciaron su colaboración, pretendían simplemente indagar en la historia de las imágenes utilizadas para ‘reconocer’ a los humanos en los ordenadores y sistemas IA. De ahí comenzarían a profundizar en cómo estos ‘motores de visión’ funcionan en la actualidad. Así, surgirían las siguientes preguntas: ¿dónde se delimitan las fronteras entre la ciencia, la historia, la política, los prejuicios y la ideología dentro de la inteligencia artificial?, y ¿quién tiene el poder de construir y beneficiarse de estos sistemas?\nAproximadamente 30,000 imágenes cubren The Curve, una de las salas del Barbican Art Gallery, que bajo el título Life Rewired, dedica un ciclo de exposiciones a indagar en lo que significa ser humano cuando la tecnología altera de forma considerable nuestras vida. Las imágenes impresas individualmente forman un mosaico, organizado según más de 200 categorías seleccionadas por el artista. Están etiquetadas de manera que el espectador puede conocer su clasificación. Proceden de ImageNet, una gigantesca base de datos creada por investigadores de las universidades de Stanford y Princeton, compuesta por fotografías clasificadas en distintas categorías que son utilizadas como imágenes de entrenamiento. “Estos sistemas tienen su propia visión del mundo”, explica Paglen en un vídeo que acompaña a la muestra. “¿Qué tipo de categorías incluyen y cuales no?, ¿qué tipo de imágenes representan esas categorías? Al observar la pieza detenidamente uno empieza a percibir las inclinaciones y políticas que pueden encerrar estos sistemas IA”.\nLa instalación se abre con una imagen de una obra del pintor René Magritte, donde se observa una manzana acompañada del texto “Esto no es una manzana”. “Sin embargo, esa pintura ha sido clasificada dentro de las imágenes de entrenamiento como una manzana. De ahí la contradicción. La cuestión de quién decide lo que significan las fotografías está en el núcleo de las cuestiones que espero que surjan con mi obra”, explica el artista. Manzanas, plátanos, cajas de cereales, cómics, animales, plantas, vehículos, son ejemplos de las categorías que abarca ImageNet. Pero hay otras destinadas a clasificar a las personas, unas 2000 categorías, donde nos encontramos por ejemplo “trabajadores\" y “líderes”. “Son clasificaciones históricas o políticas que existen en algunas culturas y en otras no“, apunta Paglen en el catálogo que acompaña a Training Humans. Es más, la idea de poder distinguir mediante la apariencia si uno es ‘líder’ es absurda: un líder en Tonga en el siglo XVII tendrá una apariencia totalmente distinta de, por ejemplo, un líder en Texas en el siglo XXI”. La cosa empeora a medida que nos encontramos con categorías como “mala persona”, “drogadicto”, “convicto”, “loco”, “fracasado”, “hipócrita”, “prostituta”, “cleptómano”, “melancólico” o “cabrón”. “Todas estas categorías están compuestas de imágenes que gente normal ha subido a Flickr u otras redes sociales. La gente que aparece en estas fotografías presuntamente no tiene ni idea de que su imagen ha sido categorizada con el propósito de adiestrar sistemas IA”, destaca el artista.\nTraining Human está planteado como un recorrido histórico a través de la evolución de los conjuntos de datos de entrenamiento utilizados, donde se exponen las inclinaciones, errores y posicionamientos ideológicos dentro de las tecnologías IA. Paglen y Crawford analizaron cómo son entendidas estas imágenes, cómo se clasifican y cuáles son las taxonomías que subyacen, para poder entender el tipo de políticas de visión incorporadas a estas nuevas tecnologías. Parten de las imágenes utilizadas en las primeras investigaciones sobre reconocimiento facial computerizado realizadas por la CIA en 1963. Así, en los años noventa encuentran conjuntos de datos de entrenamiento que muestran reminiscencias de los experimentos antropométricos realizados a últimos del siglo XIX y principios del XX, llevados a cabo por Cesare Lombroso y Alphonse Bertillon. No será hasta el 2000 cuando se empiecen a elaborar conjuntos de datos de entrenamiento basados en fotografías encontradas. “Uno de los ejemplos más inquietantes que se muestran en la exposición es Special Database 32 —Multiple Encounter Dataset II (MEDS – II)—, realizado mediante archivos policiales de criminales fallecidos, suministradas por el FBI al National Institute of Standards (NIST) “, explica Crawford. “Contiene imágenes de gente que fue arrestada varias veces, como una forma de rastreo del proceso de envejecimiento. Los protagonistas nunca dieron su permiso para que se utilizaran y fueron tomadas antes de que fueran juzgados”.\nCrawford y Paglen encontraron conjuntos de datos compuestos por miles de rostros clasificados por raza, género y edad, donde el proceso se torna muy político. “Resulta sorprendente ver cómo algunas tradiciones inherentemente opresivas encuentran eco en los sistemas contemporáneos”, explica Paglen. “En el apartheid sudafricano, la forma en la que el estado clasificaba la raza de uno determinaba si este podía trabajar, o ir al colegio y dónde vivir. Eran clasificaciones que daban a la gente acceso a distintas oportunidades. Quizás los científicos de IA no sean conscientes, pero están repitiendo esta clasificación. La clasificación de la gente mediante la raza o el género está mucho más basada en la política que en la ciencia o en la naturaleza”. Se utilizan también taxonomías clasificatorias relacionadas con el afecto y las emociones humanas basadas en las polémicas teorías del psicólogo Paul Ekman, que reducía el alcance de los sentimientos humanos a seis emociones universales. “Una de las asunciones que subyacen en los conjuntos de datos de adiestramiento en general es que conceptos como las emociones, el género, o la raza quedan expresados visualmente: se podría deducir el género, la edad o el estado emocional de una persona a través de una fotografía”.\n“Cuando observas agrupaciones como la NSA (Agencia de Seguridad Nacional de Estados Unidos) o el GCHQ (Cuartel General de Comunicaciones del Gobierno británico), una de las cosas de las que te percatas es que existen agrupaciones más grandes, como Google, que son muy parecidas en términos del tipo de datos que recopilan”, declaraba Paglen en entrevista con NewStatesman. “Comienzas a pensar en de qué van las políticas de información en general. Tal y como los historiadores de la ciencia han apuntado, los frenólogos o criminólogos de comienzos del siglo XX, que utilizaban medidas del cráneo para clasificar y ratificar las artificiales categorías raciales, no se consideraban a sí mismos unos reaccionarios políticos. Al contrario, pensaban que la ciencia moderna conduciría al hombre hacía una mayor claridad”.\nTrevor Paglen: From ‘Apple’ to ‘Anomaly'. Barbican Centre. Londres. Hasta el 26 de febrero.\nTraining Humans. Kate Crawford/Trevor Paglen. Fondazione Prada. Milán. Hasta el 24 de febrero.\n NEWSLETTER \n Recibe el boletín de Babelia \nCaixaBank apuesta por el reconocimiento facial de sus clientes para sacar dinero en los cajeros. Un sistema pionero en el mundo que demuestra las posibilidades que ofrece la biometría","url":"https://elpais.com/cultura/2019/10/31/babelia/1572528497_294245.html","newspaper":"elpais","scraper_id":"scraper_test","id":"70902501-5508-4696-4e24-279a7e2a94ca"}