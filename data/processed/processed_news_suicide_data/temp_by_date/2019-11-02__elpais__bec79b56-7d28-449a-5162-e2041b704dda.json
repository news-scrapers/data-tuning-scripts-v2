{"_id":"5dea3b30dec1220e273758f6","page":0,"fullpage":false,"headline":"Mayúsculas, exclamaciones, emojis, dibujos, imágenes y vídeos delatan los bulos","date":"2019-11-02T11:20:55.026Z","content":"Mayúsculas, exclamaciones, emojis, dibujos, imágenes y vídeos delatan los bulos\n\nEn torno a una cita casual en un bar salen algunos proyectos interesantes. De una reunión de amigos durante unas copas surgió la misión israelí a la Luna. Algo parecido ocurrió con una reciente investigación sobre las características de los bulos o fake news en Twitter, una de las principales redes sociales. A Miguel Molina, científico de datos que investigaba en el Imperial College de Londres, mientras conversaba con Juan Gómez Romero, del departamento de Ciencias de la Computación de la Universidad de Granada, se le ocurrió desarrollar un sistema para detectar los bulos. Sus resultados preliminares detectan patrones de escritura, envío y comportamiento que abren la puerta a acabar con la plaga de la desinformación. No obstante, Twitter advierte de las limitaciones de estudios similares.\n“Lo primero fue acotar el campo de investigación y definir fake news”, comenta Molina. “De forma muy resumida, son mentiras intencionadas que buscan dinero o tráfico”, explica. Esa definición coincide con otras de este mismo campo que vinculan la proliferación de noticias falsas a intentos de desestabilización, influencia y monetización.\n“Un familiar o un amigo puede pensar que está enviando información que cree que es verdadera, pero no tiene intención en ello”, explica el investigador. Con esta premisa, el equipo, con la colaboración del Imperial College, comenzó a recopilar, anotar y seleccionar tuits que respondían a su objeto de estudio.\nLa aplicación de análisis estadísticos y matemáticos sobre el material arrojó unas características particulares en la redacción de las fake news: suelen incorporar mayúsculas, exclamaciones, emojis (pictogramas), dibujos, imágenes y vídeos. “Buscan la sorpresa, llamar la atención”, argumenta Molina.\nNights of horror in Catalonia. Young pro-independence female activist kidnapped by police in Tarragona pic.twitter.com/HTJ9sXX3cw\nTuit difundido el pasado 22 de octubre en el que, encabezado con la expresión \"Noches de horror en Cataluña\", se atribuye a la policía el \"secuestro\" (Privación de libertad ambulatoria a una persona o grupo de personas, exigiendo, a cambio de su liberación, el cumplimiento de alguna condición, como puede ser el pago de un rescatede) de una \"joven\". Se trata de la detención de una mujer en Tarragona por los disturbios contra la sentencia del procés. La magistrada del Juzgado de Instrucción 1 de Tarragona, en funciones de guardia, dictó orden de prisión provisional sin fianza para la acusada.\nEste comportamiento pretende pescar en aguas de la polarización, es decir, “funcionan porque los destinatarios están dispuesto a creerse las noticias falsas”. Con esa complicidad entre emisor y receptor, la capacidad de penetración y difusión se multiplica. Su envío masivo ya consigue el efecto deseado cuando la intención es la influencia. Si, además, se quiere conseguir dinero, incluye enlaces para transferir tráfico a una determinada web con el fin de monetizar las visitas o atraer compras o pagos.\nEl trabajo, publicado en la revista internacional IEEE Access, analiza matemáticamente otras características de los tuits, como los metadatos que identifican la cuenta, el autor, el número de seguidores, favoritos, contactos o fecha de registro en la red social.\nTodas estas características, filtradas por un programa informático, han permitido determinar que las cuentas que comparten información errónea se crean vinculadas a un episodio (disturbios en Cataluña, elecciones, Brexit) concreto de la actualidad. De esta forma, además de tener más opciones de captar la atención al sumarse a temas que son tendencia, se benefician de un menor tiempo de los equipos de la red social y ajenos para que sean verificadas.\nTambién han detectado que las cuentas de fake news usan caracteres extraños tanto en su nombre como en su descripción, y tienen pocos seguidores, pero sí siguen a muchos usuarios a los que intentan ganar con su adhesión y que sirvan de correa de transmisión. Este comportamiento, conocido como reciprocidad altruista, permite que «la creación de enlaces dirigidos a otros nodos impulse a los segundos a corresponder mediante la creación de un vínculo con el primero», según la investigación.\nDe esta forma, ya sean creados por robots o por personas, tanto en su creación como en la estrategia de difusión buscan explotar sesgos humanos conocidos, como el de confirmación (tendencia a favorecer, buscar y recordar la información que confirma las propias creencias) o como el mencionado de reciprocidad altruista.\nEl modelo desarrollado por Molina y Gómez con la colaboración del Imperial College permite establecer una clasificación numérica sobre las probabilidades de que el tuit analizado sea un bulo. De esta forma, se puede establecer un código numérico (50% de ser fake news) o de colores (rojo o verde) para advertir al lector de que podría encontrarse ante una mentira intencionada.\nLos sistemas actuales de verificación manual no son capaces de responder a todo el tráfico que se genera, circunstancia que aprovechan los propagadores de bulos para inundar las redes. Con un algoritmo matemático, al menos se podría preavisar a los usuarios de qué tipo de información están recibiendo y las probabilidades de que se trate de una falsedad, explica Molina.\nTwitter advierte de las limitaciones de estos programas\nLa red social ha agradecido la investigación y reitera que para proyectos similares ponen a disposición del público de forma gratuita los datos de su interfaz de programación de aplicaciones (API). \"Ningún otro servicio o plataforma hace esto\", afirman fuentes de la compañía.\nSin embargo, la red social recuerda que su director de Integridad, Yoel Roth, ya ha advertido de los defectos y fallos en la investigación de bots o mensajes creados de forma automática. \"Vemos una gran cantidad de investigaciones (...) que realizan evaluaciones exhaustivas de los comportamientos de la cuenta utilizando solo señales públicas, como la ubicación (si se cita), el contenido de la cuenta, la frecuencia de tuits y las cuentas que siguen. Para ser claros: ninguno de estos indicadores es suficiente para determinar la atribución definitivamente. Buscar cuentas que se parezcan a las divulgadas es un enfoque igualmente defectuoso, dado que muchos de los malos actores imitan las cuentas legítimas para parecer creíbles. Este enfoque también a menudo captura erróneamente las voces legítimas que comparten un punto de vista político particular con el que uno no está de acuerdo\".\n\"Antes de participar en este tipo de investigación y hacer estas afirmaciones, se deben considerar las normas éticas. Hacer lo contrario no promueve el conocimiento público, sino que corre el riesgo de socavar profundamente la confianza en el debate público y la conversación\", advierte Roth.\n NEWSLETTER \n Recibe la mejor información en tu bandeja de entrada \nCaixaBank apuesta por el reconocimiento facial de sus clientes para sacar dinero en los cajeros. Un sistema pionero en el mundo que demuestra las posibilidades que ofrece la biometría","url":"https://elpais.com/tecnologia/2019/10/24/actualidad/1571910601_654178.html","newspaper":"elpais","scraper_id":"scraper_test","id":"bec79b56-7d28-449a-5162-e2041b704dda"}