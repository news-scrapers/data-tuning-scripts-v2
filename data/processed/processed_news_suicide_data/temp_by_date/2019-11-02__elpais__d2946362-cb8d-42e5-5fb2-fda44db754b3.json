{"_id":"5dea3b30dec1220e273758d7","page":0,"fullpage":false,"headline":"Ver para no creer","date":"2019-11-02T11:20:55.026Z","content":"Ver para no creer\n\nDonald Trump anunció la erradicación del sida en el mundo hace un par de semanas. En realidad no fue él, sino un deepfake, un vídeo falseado con herramientas de inteligencia artificial. Una ONG francesa manipuló la imagen y la voz del presidente estadounidense para transmitir un mensaje que jamás salió de su boca. Al final del vídeo, un rótulo indicaba que se trataba de un montaje. A sus responsables les llovieron críticas por haber basado su campaña en un fraude, pero consiguieron millones de visitas en Internet.\nLos deepfake, falsedades ultrarrealistas, nacieron apenas hace dos años. Se basan en la tecnología GAN (Generative Adversarial Networks, en inglés) o redes generativas antagónicas: en una explicación de brocha gorda, hay dos agentes que compiten entre sí. Uno genera contenido e intenta engañar al otro para que piense que es real; el otro discrimina lo que no le resulta creíble. Y así el sistema se va perfeccionando, aprende a crear contenido cada vez más realista.\nNo se sabe cómo van a evolucionar estas redes de creación y suplantación. No existen estándares, no hay reglas sobre qué se puede simular y qué no. Unas GAN son buenísimas generando rasgos de personalidad en vídeo, otras imitando inflexiones de voz… En medicina, por ejemplo, se están usando para generar radiografías sintéticas casi indistinguibles de las reales con las que investigar.\nEl gran negocio con el uso de GAN, por ahora, es la pornografía. Miles de actrices y cantantes americanas, coreanas y británicas se han visto protagonizando vídeos sexuales falsos en Internet. Aterroriza pensar en cómo esta tecnología pueda ser usada por abusones de instituto para humillar a compañeras.\nTambién empiezan a hacerse públicos timos financieros. En marzo, el responsable de una empresa energética en el Reino Unido recibió una llamada de su jefe en la que le pedía que hiciese una transferencia de 200.000 euros a un proveedor húngaro. En realidad la voz que ordenó el trámite había sido generada por ordenador, pero imitaba perfectamente el acento y la cadencia del jefe real. No existía el proveedor húngaro, era un ladrón, según informó The Wall Street Journal.\nEl Estado de California ha prohibido crear y distribuir vídeos deepfake 60 días antes de unas elecciones. Argumentan que bastante desafección existe ya en el electorado como para que proliferen mensajes falsos. Pero puede quedar en un parche inútil si no se educa a los ciudadanos para que tengan claro de quién se fían y por qué. Como tantos avances tecnológicos, este nos pone en un aprieto filosófico: cuando la realidad es indistinguible de la ficción, ¿cómo validamos lo que es real? Nuestros sentidos pronto nos engañarán, y nos veremos obligados a reflexionar antes de compartir, a contrastar antes de opinar. Tendremos que aprender a verificar lo que nos parecía evidente. @anafuentesf\nPuedes seguir EL PAÍS Opinión en Facebook, Twitter o suscribirte aquí a la Newsletter.\n NEWSLETTER \n Recibe el boletín de Opinión \nCaixaBank apuesta por el reconocimiento facial de sus clientes para sacar dinero en los cajeros. Un sistema pionero en el mundo que demuestra las posibilidades que ofrece la biometría\nINICIA SESIÓN PARA SEGUIR LEYENDO\nSolo con tener una cuenta ya puedes leer este artículo, es gratis.\nGracias por leer EL PAÍS\n¿No estás registrado? Crea tu cuenta","url":"https://elpais.com/elpais/2019/11/01/opinion/1572631550_328877.html","newspaper":"elpais","scraper_id":"scraper_test","id":"d2946362-cb8d-42e5-5fb2-fda44db754b3"}