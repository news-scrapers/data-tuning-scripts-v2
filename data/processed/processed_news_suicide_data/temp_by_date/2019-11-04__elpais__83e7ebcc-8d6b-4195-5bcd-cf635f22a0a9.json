{"_id":"5dea3abcdec1220e273755e3","page":0,"fullpage":false,"headline":"YouTube investiga cómo mejorar recomendaciones y aumentar el tiempo de conexión","date":"2019-11-04T11:20:55.026Z","content":"YouTube investiga cómo mejorar recomendaciones y aumentar el tiempo de conexión\n\n“¿Cuánto podrían haber mejorado nuestros últimos momentos juntos si no fuera por los delirios inducidos por YouTube?”. El pasado mes de septiembre el hijo de un científico retirado de 80 años contó cómo su padre su padre se sumergió en una espiral tóxica de vídeos durante sus últimos años. Lo hizo a través de una campaña de la Fundación Mozilla, creada para concienciar sobre los problemas generados por el algoritmo de recomendaciones de esta popular plataforma de vídeos. Ahora, varios investigadores de la compañía Google, propietaria de la plataforma audiovisual, han propuesto una modificación de este algoritmo que mejoraría las recomendaciones y aumentaría el tiempo que los usuarios permanecen conectados.\nLa inteligencia artificial controla gran parte de la información que se consume hoy en día en Internet. Los algoritmos creados por las distintas plataformas “observan la actividad de los usuarios e infieren cosas que le puedan interesar y se las proponen”, explica Pablo Castells, profesor titular de la Escuela Politécnica Superior de la Universidad Autónoma de Madrid. “Hay muchas maneras de hacerlo, desde la más trivial, como es ofrecer simplemente lo más popular, hasta formas más complejas que implican fijarse en el comportamiento de cada usuario individual”.\nEn el caso de YouTube, la plataforma hace una primera lista de recomendaciones con varios cientos de vídeos relacionados con el que está viendo el usuario y luego va refinando dicha lista teniendo en cuenta sus clics, gustos y otras interacciones. El resultado es que de los mil millones de horas que se ven cada día en esta plataforma, un 70% corresponde a vídeos recomendados por el algoritmo.\nLas distintas plataformas trabajan por mejorar este sistema, hacerlo aún más preciso y mantener durante unos minutos más a los usuarios delante de la pantalla y esto es lo que parece haber conseguido un equipo de investigadores de YouTube, según un artículo publicado en la revista ACM Digital Library. “Demostramos que nuestras propuestas pueden conducir a mejoras sustanciales en la calidad de las recomendaciones”, afirma el estudio.\nPara refinar las recomendaciones, los investigadores probaron a dar más importancia a los vídeos que se encuentran en la parte baja del listado, ya que se entiende que si el usuario ha hecho clic en esos vídeos es porque ha dedicado cierto tiempo a buscarlo. Gracias a esta modificación los desarrollares del nuevo algoritmo aseguran que han conseguido “mejoras sustanciales tanto en las métricas de compromiso como en las de satisfacción”.\n“Es una forma inteligente de abordar el problema”, asegura Castells, “ya que sabemos que hay zonas de la pantalla que están más expuestas, por lo que conseguir un clic en esa zona tiene menos mérito que el que se consigue en un elemento que está más escondido”.\nSin embargo, este tipo modificación sigue sin resolver uno de los grandes problemas que poseen estos algoritmos. Debido a que el sistema está optimizado para que los usuarios sigan viendo vídeos, éste tiende a ofrecer recomendaciones que refuerzan los gustos o creencias del usuario, lo que puede crear una experiencia que excluya otras opiniones y estimule la generación de lo que se conoce como cámaras de eco.\nEn este sentido, una investigación de Google sobre el impacto de los sistemas de recomendación, publicada a principios de este año, concluyó que \"los bucles de retroalimentación en los sistemas de recomendación pueden dar lugar a cámaras de eco', lo que puede reducir la exposición de un usuario al contenido y, en última instancia, cambiar su visión del mundo\".\nLos algoritmos creados por las distintas plataformas “observan la actividad de los usuarios e infieren cosas que le puedan interesar y se las proponen”, explica Pablo Castells, profesor titular de la Escuela Politécnica Superior de la Universidad Autónoma de Madrid\nTambién diversos estudios realizados en los últimos años, incluyendo un experimento desarrollado por periodistas de EL PAÍS, han mostrado que el algoritmo suele recompensar los vídeos más extremos y controvertidos, aunque estén repletos de bulos. “Hace tres años, mi exesposa, que padece problemas mentales, comenzó a ver vídeos de teorías de la conspiración y se los creyó todos. YouTube no dejó de alimentar su paranoia, miedos y ansiedades con vídeos, uno tras otro”, afirma otro de los testimonios recopilados por la Fundación Mozilla.\n“En la comunidad de algoritmos de recomendación hay una preocupación creciente en este sentido y cada vez hay más esfuerzos para promover una recomendación responsable”, asegura Castells. Según este especialista, hay que tener en cuenta que “los objetivos del usuario y de las empresas no están necesariamente alineados, ya que la empresa necesita que el usuario esté contento, pero de una manera que sea rentable y eso se consigue si el usuario está más tiempo conectado”. El problema, asegura este investigador, “es que el algoritmo no sabe cuándo el usuario está contento y cuándo ha entrado en un modo compulsivo\".\nEl algoritmo también ha sido cuestionado por su falta de idoneidad a la hora de ofrecer contenidos infantiles. Según un estudio publicado este mismo año en arXiv (un repositorio de artículos científicos que no son revisados por pares), “hay un 45% de probabilidad de que un niño pequeño que sigue las recomendaciones de YouTube encuentre un vídeo inapropiado en menos de 10 clics”.\nLos autores de este estudio aseguran que el problema se encuentra en el hecho de que ciertos vídeos para adultos utilizan contenidos de vídeos infantiles y el algoritmo no los diferencia. Ejemplos hay miles dentro de la plataforma, desde dibujos en los que Mickey Mouse es atropellado por un coche, hasta otros en los que Peppa Pig aparece comiéndose a su padre.\nLa solución, según Castells, “pasaría por no ofrecer contenidos simplemente basándonos en el volumen de respuesta, sino haciendo algo más cualitativo, identificando tipos de contenido”. Sin embargo, este informático advierte no solo de la complejidad técnica del problema, sino del “dilema ético que supone decidir qué contenido es marcado como inapropiado”.\nLos problemas generados por estos algoritmos han llevado a Mozilla, una organización sin ánimo de lucro dedicada al software libre, a crear una campaña para alertar sobre ello. Gracias a esta iniciativa se han recogido cientos de testimonios de personas que se han visto afectadas por estas recomendaciones o que han visto como algún ser querido se sumergía en la espiral tóxica de YouTube. “Es triste y frustrante ver como una persona querida se hunde cada vez más en este tipo de influencia oscura, negativa y dañina”, se lamenta uno de ellos.\n NEWSLETTER \n Recibe la mejor información en tu bandeja de entrada \nCaixaBank apuesta por el reconocimiento facial de sus clientes para sacar dinero en los cajeros. Un sistema pionero en el mundo que demuestra las posibilidades que ofrece la biometría","url":"https://elpais.com/tecnologia/2019/10/31/actualidad/1572535888_516452.html","newspaper":"elpais","scraper_id":"scraper_test","id":"83e7ebcc-8d6b-4195-5bcd-cf635f22a0a9"}